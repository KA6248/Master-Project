{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM7uzNWAMHFz",
        "outputId": "24f01977-2e9b-4136-823c-b84e0460ef7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proceed (Y/n)? "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Install necessary NLP libraries compatible with Google Colab base environment.\n",
        "These include Arabert, HuggingFace Transformers, Datasets, and Evaluate.\n",
        "\"\"\"\n",
        "!pip uninstall transformers --quiet\n",
        "!pip install transformers==4.41.1 --quiet\n",
        "!pip install arabert\n",
        "!pip install datasets\n",
        "!pip install evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB_GKiGjF-Br"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJF9qa6-gJ8V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUKzjPHoMYFY",
        "outputId": "13248270-b44c-45e6-80f2-ebda59efdba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version: 2.6.0+cu124\n",
            "Matplotlib version: 3.10.0\n",
            "Transformers version: 4.41.1\n",
            "Datasets version: 2.14.4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib\n",
        "import transformers\n",
        "import datasets\n",
        "import evaluate\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"Matplotlib version:\", matplotlib.__version__)\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"Datasets version:\", datasets.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATFg9IscMiU0",
        "outputId": "938dc7ff-b65f-464c-d8a9-0a69883b78f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Project structure created with the following files:\n",
            "- data_loader.py\n",
            "- preprocessing.py\n",
            "- models.py\n",
            "- trainer.py\n",
            "- run_training.py\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell creates a modular folder structure for the NLP Political Bias project,\n",
        "and generates placeholder Python files for each logical component.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "# Define base project folder\n",
        "project_dir = \"/content/nlp_project\"\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "# Define target files\n",
        "files = {\n",
        "    \"data_loader.py\": \"# data_loader.py - Loads and prepares the filtered dataset\\n\\n\",\n",
        "    \"preprocessing.py\": \"# preprocessing.py - Cleans and normalizes Arabic text\\n\\n\",\n",
        "    \"models.py\": \"# models.py - Loads and configures the desired transformer model\\n\\n\",\n",
        "    \"trainer.py\": \"# trainer.py - Handles training logic, metrics, and weighted loss\\n\\n\",\n",
        "    \"run_training.py\": \"# run_training.py - Main execution entry point for training the model\\n\\n\"\n",
        "}\n",
        "\n",
        "# Create each file with a basic header\n",
        "for filename, header in files.items():\n",
        "    path = os.path.join(project_dir, filename)\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(header)\n",
        "\n",
        "print(\" Project structure created with the following files:\")\n",
        "for fname in files:\n",
        "    print(\"-\", fname)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7CYV6Zrl-K0",
        "outputId": "2cefa0b9-1d41-4970-c22b-b23eea888440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Cleaned merged dataset saved to: /content/merged_bias_data_cleaned.csv\n",
            "üìä Dataset Shape: (11968, 5)\n",
            "\n",
            "üßæ Columns: ['label', 'text', 'explicit_type', 'bias_domain', 'label_id']\n",
            "\n",
            "üßπ Missing Values:\n",
            " label            0\n",
            "text             0\n",
            "explicit_type    0\n",
            "bias_domain      0\n",
            "label_id         0\n",
            "dtype: int64\n",
            "\n",
            "üìã Label Counts:\n",
            " label\n",
            "Unbiased                    6817\n",
            "Biased against Palestine    2300\n",
            "Biased against Israel       1981\n",
            "Biased against Muslims       542\n",
            "Biased against Jews          328\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìã Bias Domain Counts:\n",
            " bias_domain\n",
            "Political    11098\n",
            "Religious      870\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìã Explicit Type Counts:\n",
            " explicit_type\n",
            "neutral     6817\n",
            "Implicit    4449\n",
            "Explicit     702\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìà Word Count Stats:\n",
            " count    11968.000000\n",
            "mean        35.214405\n",
            "std         61.571085\n",
            "min          1.000000\n",
            "25%         11.000000\n",
            "50%         17.000000\n",
            "75%         34.000000\n",
            "max       1000.000000\n",
            "Name: word_count, dtype: float64\n",
            "\n",
            "üìä Label √ó Bias Domain:\n",
            " bias_domain               Political  Religious\n",
            "label                                         \n",
            "Biased against Israel          1981          0\n",
            "Biased against Jews               0        328\n",
            "Biased against Muslims            0        542\n",
            "Biased against Palestine       2300          0\n",
            "Unbiased                       6817          0\n",
            "\n",
            "üìä Label √ó Explicit Type:\n",
            " explicit_type             Explicit  Implicit  neutral\n",
            "label                                                \n",
            "Biased against Israel          204      1777        0\n",
            "Biased against Jews            152       176        0\n",
            "Biased against Muslims         302       240        0\n",
            "Biased against Palestine        44      2256        0\n",
            "Unbiased                         0         0     6817\n"
          ]
        }
      ],
      "source": [
        "# This will execute the data_loader.py script as if it were run directly\n",
        "!python /content/nlp_project/data_loader.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOZ14Xynwiwp"
      },
      "source": [
        "# üß† Project Dataset Overview: Arabic Bias Detection\n",
        "\n",
        "This summary documents the key characteristics and imbalances in the dataset used for Arabic bias classification (political and religious), based on the merged file:  \n",
        "üìÑ `/content/merged_bias_data_cleaned.csv`\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Dataset Size and Structure\n",
        "\n",
        "- **Total samples**: `11,968`\n",
        "- **Columns**:\n",
        "  - `text`: the input sentence\n",
        "  - `label`: the bias label (in English)\n",
        "  - `explicit_type`: nature of the bias expression (Explicit/Implicit/Neutral)\n",
        "  - `bias_domain`: the domain of bias (Political/Religious)\n",
        "  - `label_id`: numeric encoding of the label\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Label Distribution\n",
        "\n",
        "| Label                    | Count | Percentage |\n",
        "|--------------------------|-------|------------|\n",
        "| Unbiased                 | 6817  | 57.0% üî∫ |\n",
        "| Biased against Palestine | 2300  | 19.2% |\n",
        "| Biased against Israel    | 1981  | 16.5% |\n",
        "| Biased against Muslims   | 542   | 4.5% üîª |\n",
        "| Biased against Jews      | 328   | 2.7% üîª |\n",
        "\n",
        "> ‚ö†Ô∏è **Observation**: Strong class imbalance. Over 57% of the data is \"Unbiased\", while \"Biased against Jews/Muslims\" are significantly underrepresented.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ Bias Domain Distribution\n",
        "\n",
        "| Domain     | Count | Percentage |\n",
        "|------------|--------|------------|\n",
        "| Political  | 11098  | 92.7% |\n",
        "| Religious  | 870    | 7.3% üîª |\n",
        "\n",
        "> ‚ö†Ô∏è **Observation**: Religious bias data is limited, likely requiring sampling or augmentation for balance.\n",
        "\n",
        "---\n",
        "\n",
        "## üí¨ Explicit Type Distribution\n",
        "\n",
        "| Type      | Count | Percentage |\n",
        "|-----------|--------|------------|\n",
        "| Neutral   | 6817   | 57.0% üî∫ |\n",
        "| Implicit  | 4449   | 37.2% |\n",
        "| Explicit  | 702    | 5.9% üîª |\n",
        "\n",
        "> ‚ö†Ô∏è **Observation**: Majority of \"neutral\" samples overlap with \"Unbiased\". Explicit examples are rare and underrepresented.\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Word Count Statistics\n",
        "\n",
        "- **Mean**: 35.2 words\n",
        "- **Median**: 17 words\n",
        "- **Max**: 1000 words\n",
        "- **Min**: 1 word\n",
        "\n",
        "> ‚ö†Ô∏è **Recommendation**: Consider truncating or padding inputs to `max_length = 256` for training with transformer models.\n",
        "\n",
        "---\n",
        "\n",
        "## üîÄ Cross Analysis: Label √ó Domain\n",
        "\n",
        "- Political bias is associated exclusively with:\n",
        "  - Biased against Israel / Palestine / Unbiased\n",
        "- Religious bias includes:\n",
        "  - Biased against Muslims / Jews\n",
        "\n",
        "## üîÄ Cross Analysis: Label √ó Explicit Type\n",
        "\n",
        "| Label                    | Explicit | Implicit | Neutral |\n",
        "|--------------------------|----------|----------|---------|\n",
        "| Biased against Palestine | 44       | 2256     | 0       |\n",
        "| Biased against Israel    | 204      | 1777     | 0       |\n",
        "| Biased against Muslims   | 302      | 240      | 0       |\n",
        "| Biased against Jews      | 152      | 176      | 0       |\n",
        "| Unbiased                 | 0        | 0        | 6817 ‚úÖ |\n",
        "\n",
        "> ‚úÖ **Pattern**: Neutral bias type only exists in \"Unbiased\" samples.\n",
        "> ‚ö†Ô∏è **Explicit bias underrepresented** across all categories.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Summary of Key Issues\n",
        "\n",
        "- **Label Imbalance**:\n",
        "  - \"Unbiased\" dominates.\n",
        "  - Rare representation of religious bias categories.\n",
        "\n",
        "- **Explicit Type Imbalance**:\n",
        "  - Very few explicit bias examples.\n",
        "  - Most biased samples are implicit.\n",
        "\n",
        "- **Domain Imbalance**:\n",
        "  - Political bias is overwhelming compared to religious bias.\n",
        "\n",
        "- **Long Tail in Text Length**:\n",
        "  - Some samples are extremely long (up to 1000 words), requiring truncation.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ† Next Steps (Recommended)\n",
        "\n",
        "1. Remove 50% of \"Unbiased\" and/or \"neutral\" examples.\n",
        "2. Apply `class_weight` in training or use weighted sampling.\n",
        "3. Explore data augmentation for underrepresented classes.\n",
        "4. Optional: Multi-task learning with both `label` and `explicit_type`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoyodMkm_g6l"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}